{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vietnamese-Q&A-wiki.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNin2oz6CDOxW3PAxqkcAHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koyomin9zx/UITQA-Vietnamese-Question-Answering/blob/master/Vietnamese_Q%26A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwGlBWUyHxBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "acef9309-188f-4922-fa94-b0f0508ba416"
      },
      "source": [
        "#Requirements\n",
        "!pip install --upgrade google-api-python-client\n",
        "!pip install nltk\n",
        "!pip install BeautifulSoup\n",
        "!pip install underthesea\n",
        "!pip install sklearn\n",
        "!pip install plotly"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google-api-python-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 34.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 40kB 38.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 51kB 26.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (0.17.1)\n",
            "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (0.0.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client) (46.1.3)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (1.51.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client) (1.24.3)\n",
            "Installing collected packages: google-api-python-client\n",
            "  Found existing installation: google-api-python-client 1.7.12\n",
            "    Uninstalling google-api-python-client-1.7.12:\n",
            "      Successfully uninstalled google-api-python-client-1.7.12\n",
            "Successfully installed google-api-python-client-1.8.0\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Collecting BeautifulSoup\n",
            "  Downloading https://files.pythonhosted.org/packages/40/f2/6c9f2f3e696ee6a1fb0e4d7850617e224ed2b0b1e872110abffeca2a09d4/BeautifulSoup-3.2.2.tar.gz\n",
            "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "Collecting underthesea\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/e8/832becde9ee2b14f81620e11e6417a882184756bdadc4399f096a9b6c94c/underthesea-1.1.17-py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 19.9MB/s \n",
            "\u001b[?25hCollecting nltk<3.5,>=3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 43.1MB/s \n",
            "\u001b[?25hCollecting python-crfsuite==0.9.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/86/cfcd71edca9d25d3d331209a20f6314b6f3f134c29478f90559cee9ce091/python_crfsuite-0.9.6-cp36-cp36m-manylinux1_x86_64.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 46.7MB/s \n",
            "\u001b[?25hCollecting languageflow==1.1.13a1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/be/62db3c61f872bbdd7d18671442601e6f59c4fb8004d73a03162f5b2bcc02/languageflow-1.1.13a1-py2.py3-none-any.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 48.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from underthesea) (7.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk<3.5,>=3.4->underthesea) (1.12.0)\n",
            "Collecting clint\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/b4/41ecb1516f1ba728f39ee7062b9dac1352d39823f513bb6f9e8aeb86e26d/clint-0.5.1.tar.gz\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from languageflow==1.1.13a1->underthesea) (0.8.7)\n",
            "Collecting scikit-learn==0.20.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/82/c0de5839d613b82bddd088599ac0bbfbbbcbd8ca470680658352d2c435bd/scikit_learn-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4MB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from languageflow==1.1.13a1->underthesea) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from languageflow==1.1.13a1->underthesea) (2.21.0)\n",
            "Collecting joblib==0.13.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 52.9MB/s \n",
            "\u001b[?25hCollecting args\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/1c/b701b3f4bd8d3667df8342f311b3efaeab86078a840fb826bd204118cc6b/args-0.1.0.tar.gz\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.3->languageflow==1.1.13a1->underthesea) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.3->languageflow==1.1.13a1->underthesea) (1.18.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->languageflow==1.1.13a1->underthesea) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->languageflow==1.1.13a1->underthesea) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->languageflow==1.1.13a1->underthesea) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->languageflow==1.1.13a1->underthesea) (2020.4.5.1)\n",
            "Building wheels for collected packages: nltk, clint, args\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449906 sha256=4f6fba7656d4fc6fa3dbea1770490ee000e50c36fa44ddfaedc94bb2407d49d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for clint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clint: filename=clint-0.5.1-cp36-none-any.whl size=34449 sha256=a85ecc99525b4a7877e669bf6a5d1029d1c1b0fcfa705a208da9a2f4b6d18d11\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/e9/45/223565e5b1a4b09e12c6de6f8ba7c2c0e9127dec17cf830f83\n",
            "  Building wheel for args (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for args: filename=args-0.1.0-cp36-none-any.whl size=3320 sha256=fc0abaee6d12aee7a4a6a99166bbeb69c7cbebaffa20e55e396d9fbbdb4d2f74\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/54/ea/d995d18af68c057eb76b87b02c92bc66ac34d360ef141780f4\n",
            "Successfully built nltk clint args\n",
            "Installing collected packages: nltk, python-crfsuite, args, clint, scikit-learn, joblib, languageflow, underthesea\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: joblib 0.14.1\n",
            "    Uninstalling joblib-0.14.1:\n",
            "      Successfully uninstalled joblib-0.14.1\n",
            "Successfully installed args-0.1.0 clint-0.5.1 joblib-0.13.2 languageflow-1.1.13a1 nltk-3.4.5 python-crfsuite-0.9.6 scikit-learn-0.20.3 underthesea-1.1.17\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly) (1.12.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly) (1.3.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byNYORPPIX9Z",
        "colab_type": "code",
        "outputId": "021cdbf5-9c02-4674-ff3d-07d05b4c21dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import pickle\n",
        "from googleapiclient.discovery import build\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import timeit\n",
        "import time\n",
        "from multiprocessing import Pool\n",
        "import string\n",
        "import numpy as np\n",
        "from difflib import SequenceMatcher\n",
        "from nltk import sent_tokenize, download\n",
        "from underthesea import word_tokenize\n",
        "from underthesea import ner\n",
        "from collections import defaultdict\n",
        "\n",
        "download('punkt')\n",
        "Seach_api_key =\"AIzaSyBy-PVoHZdYRDU70gsLD-ALy5JabcZUICk\"\n",
        "Custom_Search_Engine_ID =\"005336700654283051786:1mzldt1husk\"\n",
        "\n",
        "stopwords = set(open('stopwords.txt').read().split('\\n')[:-1]) #set stopword\n",
        "puct_set = set([c for c in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~']) #set puctua\n",
        "\n",
        "def tokenize(text):\n",
        "    sents = sent_tokenize(text)\n",
        "    sents = [word_tokenize(s,format = 'text') for s in sents]\n",
        "    return sents\n",
        "\n",
        "def get_entities(seq):\n",
        "    i = 0\n",
        "    chunks = []\n",
        "    seq = seq + ['O']  # add sentinel\n",
        "    types = [tag.split('-')[-1] for tag in seq]\n",
        "    while i < len(seq):\n",
        "        if seq[i].startswith('B'):\n",
        "            for j in range(i+1, len(seq)):\n",
        "                if seq[j].startswith('I') and types[j] == types[i]:\n",
        "                    continue\n",
        "                break\n",
        "            chunks.append((types[i], i, j))\n",
        "            i = j\n",
        "        else:\n",
        "            i += 1\n",
        "    return chunks\n",
        "\n",
        "def _get_chunks(words, tags):\n",
        "    chunks = get_entities(tags)\n",
        "    res = defaultdict(list)\n",
        "    for chunk_type, chunk_start, chunk_end in chunks:\n",
        "        res[chunk_type].append(' '.join(words[chunk_start: chunk_end]))\n",
        "    return res\n",
        "\n",
        "def ner_extraction(text):\n",
        "    res = ner(text)\n",
        "    words = [r[0] for r in res]\n",
        "    tags = [t[3] for t in res]\n",
        "    \n",
        "    return _get_chunks(words,tags)\n",
        "\n",
        "def generateBigram(words):\n",
        "    bigrams = [words[i] + '_' + words[i+1] for i in range(0,len(words) - 1)]\n",
        "    return bigrams\n",
        "\n",
        "def noiseSent(sent):\n",
        "    if len(sent.split()) <= 3 or len(sent.split()) > 100:\n",
        "        return True\n",
        "    \n",
        "    if len(sent) <= 30:\n",
        "        return True\n",
        "    \n",
        "    if all(ord(c) < 128 for c in sent):\n",
        "        return True\n",
        "    \n",
        "    if not any(c.isalpha() for c in sent):\n",
        "        return True\n",
        "\n"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sI6LEtLKeI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Passage:\n",
        "    def __init__(self,string,rank,num_key):\n",
        "        self.sent = string            #sentences\n",
        "        self.ner = []                 #named entities\n",
        "        self.num_key = num_key        #number of match keywords\n",
        "        self.len_long_seq = 0         #length of longest exact sequence of question keywords\n",
        "        self.rank = rank              #rank of own document\n",
        "        self.ngram_overlap = 0        #ngram overlap question\n",
        "        self.proximity = 0            #shortest keywords that cover all keywords\n",
        "        self.score = 0                #Overall score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qEauYTNg89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keywords_extraction(sentences):\n",
        "    sent = sentences.lower()\n",
        "    sent = sent.split()\n",
        "    sent = [s for s in sent if s not in stopwords and s not in puct_set]\n",
        "    return sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-zOoQe0NxUq",
        "colab_type": "code",
        "outputId": "75d56f8c-5ae3-42cd-af2b-f88b55d5c1ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "query =\"Người phát minh ra điện xoay chiều?\"\n",
        "\n",
        "token_query = tokenize(query)[0]\n",
        "keywords = keywords_extraction(token_query)\n",
        "print(token_query)\n",
        "print('Keywords : ' + ' , '.join(keywords))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Người phát_minh ra điện xoay_chiều ?\n",
            "Keywords : người , phát_minh , ra , điện , xoay_chiều\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgXmeqVxOvhu",
        "colab_type": "code",
        "outputId": "2298979b-fbb0-46fb-a4a0-dcad09dde89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "start = time.time()\n",
        "service = build(\"customsearch\", \"v1\",developerKey=Seach_api_key)\n",
        "\n",
        "def ggsearch(i):\n",
        "    if (i == 0):\n",
        "        res = service.cse().list(q=query,cx = Custom_Search_Engine_ID).execute()\n",
        "    else:\n",
        "        res = service.cse().list(q=query,cx = Custom_Search_Engine_ID,num=10,start = i*10).execute()\n",
        "    return res['items']\n",
        "\n",
        "#multi processing\n",
        "pool = Pool(4)\n",
        "pages_content = pool.map(ggsearch,range(3))\n",
        "pool.terminate()\n",
        "#pages_content=ggsearch(1)\n",
        "\n",
        "#extract url, title\n",
        "pages_content = [j for i in pages_content for j in i]\n",
        "document_urls = []\n",
        "document_titles = []\n",
        "for page in pages_content:\n",
        "    if 'fileFormat' in page:\n",
        "        print('Skip ' +  page['link'])\n",
        "        continue\n",
        "    document_urls.append(page['link'])\n",
        "    document_titles.append(page[u'title'])\n",
        "    \n",
        "for i in range(0,10):\n",
        "    print(document_titles[i])\n",
        "    print(document_urls[i])\n",
        "\n",
        "print('Number of result: '+str(len(document_titles)))\n",
        "print('Time execute: '+str(time.time() - start))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuộc đời bi thảm của 'cha đẻ' dòng điện xoay chiều - Giáo dục ...\n",
            "https://news.zing.vn/cuoc-doi-bi-tham-cua-cha-de-dong-dien-xoay-chieu-post836500.html\n",
            "Nikola Tesla – Wikipedia tiếng Việt\n",
            "https://vi.wikipedia.org/wiki/Nikola_Tesla\n",
            "6 phát minh nổi tiếng ban đầu bị chê thậm tệ - Tuổi Trẻ Online\n",
            "https://tuoitre.vn/6-phat-minh-noi-tieng-ban-dau-bi-che-tham-te-20180605142523281.htm\n",
            "Thomas Edison – Wikipedia tiếng Việt\n",
            "https://vi.wikipedia.org/wiki/Thomas_Edison\n",
            "10 phát minh \"không tưởng\" của Nikola Tesla - KhoaHoc.tv\n",
            "https://khoahoc.tv/10-phat-minh-khong-tuong-cua-nikola-tesla-55948\n",
            "Phát minh ra thủy điện, tia X, Tesla lẽ ra phải được công nhận từ lâu ...\n",
            "https://baomoi.com/phat-minh-ra-thuy-dien-tia-x-tesla-le-ra-phai-duoc-cong-nhan-tu-lau/c/32809757.epi\n",
            "NIKOLA TESLA | Hành Trình Lập Chí Vĩ Đại\n",
            "https://www.hanhtrinhlapchividai.com/mat-ma-thanh-cong/vi-nhan/nikola-tesla-p266.html\n",
            "George Westinghouse – Wikipedia tiếng Việt\n",
            "https://vi.m.wikipedia.org/wiki/George_Westinghouse\n",
            "Thí nghiệm của Edison đã khiến cả thế giới giật mình vì sự tàn nhẫn ...\n",
            "https://kenh14.vn/thi-nghiem-gay-tranh-cai-cua-edison-da-khien-ca-the-gioi-giat-minh-vi-su-tan-nhan-cua-con-nguoi-20160127183026295.chn\n",
            "Mừng sinh nhật Nikola Tesla, hãy cùng điểm lại tiểu sử của một ...\n",
            "https://m.genk.vn/mung-sinh-nhat-nikola-tesla-hay-cung-diem-lai-tieu-su-cua-mot-trong-nhung-nha-phat-minh-loi-lac-nhat-lich-su-loai-nguoi-20170711121920655.chn\n",
            "Number of result: 30\n",
            "Time execute: 0.48015713691711426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS1yLfL6UBQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37c28dc3-8073-41cb-d410-c36382aa925c"
      },
      "source": [
        "passages = []\n",
        "total_start = time.time()\n",
        "    \n",
        "#set a limit on number of character extract from url\n",
        "def chunks(text, number):\n",
        "    for i in range(0, len(text), number):\n",
        "        yield text[i:i + number]\n",
        "\n",
        "def getContent(para):\n",
        "    url = para[0]\n",
        "    rank = int((para[1] + 10)/10) - 1 \n",
        "    passages = []\n",
        "    try:\n",
        "        html = requests.get(url, timeout = 5)\n",
        "    except:\n",
        "        print('Cannot read ' + url)\n",
        "        return []\n",
        "    \n",
        "    tree = BeautifulSoup(html.text,'lxml')\n",
        "    for invisible_elem in tree.find_all(['script', 'style']):\n",
        "        invisible_elem.extract()\n",
        "    \n",
        "    sents = []\n",
        "    text_chunks = list(chunks(tree.get_text(),100000))\n",
        "    for text in text_chunks:\n",
        "        sents += tokenize(text)\n",
        "    \n",
        "    for sent in sents:\n",
        "        sent = sent.strip() \n",
        "        if not noiseSent(sent):\n",
        "            sent_keywords = keywords_extraction(sent)\n",
        "            num_overlap_keywords = len(set(sent_keywords) & set(keywords))\n",
        "            if num_overlap_keywords > 0:\n",
        "                passages.append(Passage(sent,rank,num_overlap_keywords))\n",
        "                \n",
        "    return passages\n",
        "\n",
        "pool = Pool(40)\n",
        "passages = pool.map(getContent,[(document_urls[i],i) for i in range(0,len(document_urls))])\n",
        "pool.terminate()\n",
        "passages = [j for i in passages for j in i]"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cannot read http://kingteksolar.com.vn/tin-tuc/so-sanh-dien-mot-chieu-dc-va-dien-xoay-chieu-ac.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QDirpK1b4tY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0f8d82c1-2867-4e16-d21b-bad5948c8040"
      },
      "source": [
        "for i in range(0,len(passages)):\n",
        "    passages[i].ner = list(set(ner_extraction(passages[i].sent)[\"PER\"]))\n",
        "\n",
        "print('Number of passages : ' + str(len(passages)))\n",
        "passages = [p for p in passages if len(p.ner) > 0]\n",
        "print('After Filtering : ' + str(len(passages)))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of passages : 626\n",
            "After Filtering : 374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxiXDzzUi4rt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "8a995b13-8f11-409e-ef0d-d3d7175ca9ec"
      },
      "source": [
        "print( 'Total passages : ' +  str(len(passages)))\n",
        "max_keyword = 0\n",
        "min_num_passages = 20\n",
        "for p in passages:\n",
        "    if p.num_key > max_keyword:\n",
        "        max_keyword = p.num_key\n",
        "        \n",
        "\n",
        "while (True):\n",
        "    num_candidate_passages = 0\n",
        "    for p in passages:\n",
        "        if p.num_key >= max_keyword:\n",
        "            num_candidate_passages += 1\n",
        "    if (num_candidate_passages >= min_num_passages or max_keyword == 1):\n",
        "        break\n",
        "    else:\n",
        "        max_keyword -=1\n",
        "        \n",
        "print( 'Max number of question keyword : ' + str(max_keyword))\n",
        "passages = [p for p in passages if p.num_key >= max_keyword]\n",
        "print( 'After filtering : ' +  str(len(passages)) + '\\n')\n",
        "for i in range(0,min(12,len(passages))):\n",
        "    print( str(i) + ' - ' + passages[i].sent + '\\n')\n"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total passages : 374\n",
            "Max number of question keyword : 3\n",
            "After filtering : 45\n",
            "\n",
            "0 - Tesla vs Edison_Cuộc cạnh_tranh giữa Edison và Tesla chủ_yếu xảy ra ở lĩnh_vực điện , mà cụ_thể là dòng_điện một chiều và dòng_điện xoay_chiều .\n",
            "\n",
            "1 - Các phát_minh của Tesla và các công_trình lý_thuyết đã làm nên cơ_sở của hệ_thống phát_điện xoay_chiều , bao_gồm cả hệ_thống phân_phối điện nhiều pha và động_cơ_điện xoay_chiều , giúp tạo ra Cách_mạng công_nghiệp lần thứ hai .\n",
            "\n",
            "2 - Thậm_chí còn có một chiến_dịch tuyên_truyền \" Chiến_tranh các dòng_điện \" đang diễn ra với Edison_Electric khi cố_gắng tuyên_bố hệ_thống điện một chiều của họ tốt và an_toàn hơn hệ_thống điện xoay_chiều của Westinghouse .\n",
            "\n",
            "3 - Dòng_điện xoay_chiều Dòng_điện xoay_chiều của Tesla từng bị chỉ_trích có_thể gây chết ngườiEdison là người sáng_tạo ra bóng_đèn dây_tóc , đồng_thời cũng là người ủng_hộ dòng_điện một chiều .\n",
            "\n",
            "4 - Máy_bay Chuyến bay 12 giây ngắn_ngủi của anh_em nhà WrightAnh em nhà Wright được xem là người phát_minh ra máy_bay khi vào năm 1903 thực_hiện chuyến bay lịch_sử kéo_dài 12 giây .\n",
            "\n",
            "5 - Ví_dụ , trái với điều mọi người vẫn nghĩ , Edison không phát_minh ra bóng đèn điện .\n",
            "\n",
            "6 - Trong khi những nhà phát_minh trước đó đã sản_xuất ra đèn_điện trong các điều_kiện phòng_thí_nghiệm , Edison đã tập_trung vào việc áp_dụng thương_mại_hóa và đã có_thể bán ý_tưởng của mình tới các gia_đình và các cửa_hàng bằng cách sản_xuất hàng_loạt các bóng_đèn có tuổi_thọ cao và tạo ra một hệ_thống phát và cung_cấp điện .\n",
            "\n",
            "7 - George_Westinghouse và Edison đã trở_thành đối_thủ vì Edison xúc_tiến việc sử_dụng dòng_điện một_chiều ( DC ) cho phân_phối điện trong hệ_thống luân_phiên thay_vì một hệ_thống đơn_giản hơn là dòng_điện xoay_chiều ( AC ) được phát_minh bởi Nikola_Tesla và xúc_tiến bởi Westinghouse .\n",
            "\n",
            "8 - 5 dự_đoán làm thay_đổi thế_giới công_nghệ của Nikola_Tesla cách đây 1 thế_kỷ Quảng_cáo xuất_sắc của Tesla khiến hàng triệu người phải suy_nghĩ Nikola_Tesla là một nhà phát_minh , nhà vật_lý , kỹ_sư cơ_khí và kỹ_sư điện_tử được biết đến với nhiều đóng_góp mang tính cách_mạng trong các lĩnh_vực điện và từ trường trong cuối thế_kỷ 19 đầu thế_kỉ 20 .\n",
            "\n",
            "9 - Cập_nhật : 06/12/2018 Theo VTC 3,944 120.699 Xem thêm : Nikola_Tesla phát_minh của Nikola_Tesla_Máy giao động của Tesla thắp sáng thế_giới Dòng_điện xoay_chiều Tham_khảo thêm Những phát_minh kỳ_cục của người Nhật Những phát_minh kỳ_dị , không giống ai 10 phát_minh thú_vị nhất năm 2013 10 phát_minh nổi_tiếng của Isaac_Newton 6 phát_minh ấn_tượng của năm 2014 Theo_dõi cộng_đồng KhoaHoc . tv trên facebook Công_nghệ Điều gì xảy ra với cơ_thể khi rơi vào trạng_thái hôn_mê ?\n",
            "\n",
            "10 - Những phát_minh của NASA chúng_ta đang ... sử_dụng Quảng_cáo xuất_sắc của Tesla khiến hàng triệu người phải suy_nghĩ 30 ý_tưởng sửa_chữa đồ_dùng bị hỏng của các kỹ_sư \" siêu \" sáng_tạo Bí_ẩn con_số có_thể \" mở ra vũ_trụ \" của nhà_bác_học \" điên \" thiên_tài 5 dự_đoán làm thay_đổi thế_giới công_nghệ của Nikola_Tesla cách đây 1 thế_kỷ Trang_chủ .\n",
            "\n",
            "11 - \" Tesla là người đặt nên cột mốc mới cho công_nghệ không dây \" , Ivana_Zoric , người phụ_trách Bảo_tàng Nikola_Tesla ở Belgrade , Serbia cho biết , \" Tesla chính là người đàn_ông phát_minh ra thế_kỷ 20 \" . Điều_khiển từ xaNếu giờ bạn có_thể ngồi một chỗ , không cần rời khỏi ghế để chuyển kênh TV , bạn phải cảm_ơn Tesla .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EJSnoTTzH49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "437189bf-fa53-4072-9036-876445ecd17a"
      },
      "source": [
        "for i in range(0,len(passages)):\n",
        "    score = 3\n",
        "    score -= passages[i].rank\n",
        "    score -= len(passages[i].ner)\n",
        "    score += passages[i].num_key\n",
        "    score -= int(len(passages[i].sent.split()) / 50.0)\n",
        "    \n",
        "    x = token_query.lower().split()\n",
        "    y = p.sent.lower().split()\n",
        "    s = SequenceMatcher(None, x, y)\n",
        "    score += s.find_longest_match(0, len(x), 0, len(y)).size\n",
        "    \n",
        "    bigram_q = generateBigram(x)\n",
        "    bigram_p = generateBigram(y)\n",
        "    score += len(set(bigram_q) & set(bigram_p))\n",
        "    \n",
        "    passages[i].score = score\n",
        "    candidates = [p.ner for p in passages]\n",
        "    \n",
        "candidates = list(set([j for i in candidates for j in i]))\n",
        "candidates = [(c,0) for c in candidates]\n",
        "candidates = dict(candidates)\n",
        "\n",
        "for p in passages:\n",
        "    for ner in p.ner:\n",
        "        candidates[ner] += p.score\n",
        "\n",
        "candidates = candidates.items()\n",
        "\n",
        "candidates = sorted(candidates, key = lambda x: x[1],reverse = True)\n",
        "candidates = candidates[:10]\n",
        "total_score = float(sum([c[1] for c in candidates[:5]]))\n",
        "\n",
        "for c in candidates:\n",
        "    print( c[0], round((c[1] / total_score) * 100,2), \"%\")"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla 46.25 %\n",
            "Edison 26.25 %\n",
            "Nikola_Tesla 10.62 %\n",
            "Westinghouse 10.0 %\n",
            "Guglielmo_Marconi 6.88 %\n",
            "George_Westinghouse 5.62 %\n",
            "Ivana_Zoric 4.38 %\n",
            "Ví_dụ 3.75 %\n",
            "Máy_bay Chuyến 3.75 %\n",
            "Bóng_đèn Edison_Nhà 3.75 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}