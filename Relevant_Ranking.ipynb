{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Relevant_Ranking.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPCHN1Y+MdMKdGF4rirhcPK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koyomin9zx/UITQA-Vietnamese-Question-Answering/blob/master/Relevant_Ranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUAUJCSJevOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoZgXjnzYHHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -s /content/drive/'My Drive'/data_QA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVtYRivHhNqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install underthesea \n",
        "!pip install unidecode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCPkSQvyXv3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing libraries \n",
        "from underthesea import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.metrics.pairwise import cosine_similarity \n",
        "from scipy.spatial import distance \n",
        "from collections import defaultdict, OrderedDict \n",
        "from string import punctuation\n",
        "import unidecode\n",
        "import re\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKc4BrSph-4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(path):\n",
        "  data=[]\n",
        "  all_files = glob.glob(path + \"/*.txt\")\n",
        "  for file in all_files:\n",
        "      passage=open(file, \"r\", encoding='utf-8').read()\n",
        "      data.append(passage)\n",
        "  return data\n",
        "\n",
        "def vi_tokenizer(row):\n",
        "    return word_tokenize(row, format=\"text\")\n",
        "\n",
        "def remove_accents(row):\n",
        "  return unidecode.unidecode(row)\n",
        "\n",
        "def standardize_data(df):\n",
        "    hl_cleansed=[]\n",
        "    remove = punctuation\n",
        "    #remove = remove.replace(\"-\", \"\") # don't remove hyphens\n",
        "    pattern = \"[{}]\".format(remove) # create the pattern\n",
        "    re_space=re.compile('\\s+')\n",
        "    re_trailing=re.compile('^\\s+|\\s+?$')\n",
        "    for row in df:\n",
        "        row=re.sub(pattern, \" \", row) \n",
        "        row=re.sub(re_space,' ',row)\n",
        "        row=re.sub(re_trailing,' ',row)\n",
        "        row = row.strip()\n",
        "        row = vi_tokenizer(row)\n",
        "        row = remove_accents(row)\n",
        "        row = row.lower()\n",
        "        hl_cleansed.append(row)\n",
        "    return hl_cleansed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tq3XLTMfvtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Converting 3D array of array into 1D array \n",
        "def arr_convert_1d(arr): \n",
        "    arr = np.array(arr) \n",
        "    arr = np.concatenate( arr, axis=0 ) \n",
        "    arr = np.concatenate( arr, axis=0 ) \n",
        "    return arr \n",
        "   \n",
        "## Cosine Similarity \n",
        "def cosine(trans): \n",
        "    cos = [] \n",
        "    cos.append(cosine_similarity(trans[0], trans[1])) \n",
        "    return cos\n",
        "\n",
        "def tfidf(str1, str2,tf_idf_vetor):  \n",
        "    corpus = [str1,str2] \n",
        "    trans = tf_idf_vetor.transform(corpus) \n",
        "    cos=cosine(trans) \n",
        "    return arr_convert_1d(cos)[0]\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMX8O3JvqIts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "31f7db7c-9fb1-4da3-a801-2cdaa3abd761"
      },
      "source": [
        "data=load_data('/content/data_QA')\n",
        "vect = TfidfVectorizer(min_df=2, max_df=0.8,max_features=2000,sublinear_tf=True) \n",
        "vect.fit(data)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=0.8, max_features=2000,\n",
              "                min_df=2, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=True, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8f0h-m3hR1X",
        "colab_type": "code",
        "outputId": "8a4db637-33ec-4cec-e595-37748c5a0745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "query='Chu Văn An sinh năm nào?'\n",
        "\n",
        "score=defaultdict()\n",
        "for i in data:\n",
        "  t=tfidf(query, i,vect)\n",
        "  score[t]=i\n",
        "\n",
        "\n",
        "score=OrderedDict(sorted(score.items(),reverse=True))\n",
        "\n",
        "print(standardize_data([query]))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['chu_van_an_sinh nam nao']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}