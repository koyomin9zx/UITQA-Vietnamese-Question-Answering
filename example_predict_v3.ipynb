{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example_predict.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koyomin9zx/UITQA-Vietnamese-Question-Answering/blob/master/example_predict_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BslQeHl4qVUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/koyomin9zx/UITQA-Vietnamese-Question-Answering.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUKLdjyk2kAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch-transformers\n",
        "!pip install underthesea \n",
        "!pip install unidecode\n",
        "!pip install whoosh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9p5f4LHYj00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azCO_Yqt5awd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -s /content/drive/'My Drive'/data\n",
        "!mv /content/UITQA-Vietnamese-Question-Answering/combine.py /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X4w72iQ6VhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing libraries \n",
        "from underthesea import word_tokenize, sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.metrics.pairwise import cosine_similarity \n",
        "from scipy.spatial import distance \n",
        "from collections import defaultdict, OrderedDict \n",
        "from string import punctuation\n",
        "import unidecode\n",
        "import re\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import glob\n",
        "from combine import QA\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "from whoosh.fields import Schema, TEXT, STORED\n",
        "from whoosh.index import create_in, open_dir\n",
        "from whoosh.query import *\n",
        "from whoosh.qparser import QueryParser\n",
        "from underthesea import pos_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlQ8dspK2OwP",
        "colab_type": "code",
        "outputId": "f07a1a0b-6dbf-42d6-eb28-ead92654aab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "start = time.time()\n",
        "model=QA('/content/data/BERT_Squad_WIki_UIT_pretrain') #path to model\n",
        "end = time.time()\n",
        "print(\"time load model: \"+str(round((end - start),2)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time load model: 28.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvcP8N1z6bwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(path):\n",
        "  data=[]\n",
        "  all_files = glob.glob(path + \"/*.txt\")\n",
        "  for file in all_files:\n",
        "      passage=open(file, \"r\", encoding='utf-8').read()\n",
        "      data.append(passage)\n",
        "  return data\n",
        "\n",
        "def vi_tokenizer(row):\n",
        "    return word_tokenize(row, format=\"text\")\n",
        "\n",
        "def remove_stopwords(stopwords,text):\n",
        "  sent = [s for s in text.split() if s not in stopwords ]\n",
        "  sent = ' '.join(sent)\n",
        "  return sent\n",
        "\n",
        "\n",
        "def remove_punctuation(row):\n",
        "  remove = punctuation\n",
        "  remove = remove.replace(\"_\", \"\")\n",
        "  pattern = \"[{}]\".format(remove) # create the pattern\n",
        "  re_space=re.compile('\\s+')\n",
        "  re_trailing=re.compile('^\\s+|\\s+?$')\n",
        "  row=re.sub(pattern, \" \", row) \n",
        "  row=re.sub(re_space,' ',row)\n",
        "  row=re.sub(re_trailing,' ',row)\n",
        "  row = row.strip()\n",
        "  row =row.lower()\n",
        "  return row\n",
        "\n",
        "def standardize_data(df,stopwords):\n",
        "    hl_cleansed=[]\n",
        "    remove = punctuation\n",
        "    #remove = remove.replace(\"_\", \"\")\n",
        "    pattern = \"[{}]\".format(remove) # create the pattern\n",
        "    re_space=re.compile('\\s+')\n",
        "    re_trailing=re.compile('^\\s+|\\s+?$')\n",
        "    for row in df:\n",
        "        #row = vi_tokenizer(row)\n",
        "        row=re.sub(pattern, \" \", row) \n",
        "        row=re.sub(re_space,' ',row)\n",
        "        row=re.sub(re_trailing,' ',row)\n",
        "        row = row.strip()\n",
        "        row = remove_stopwords(stopwords,row)\n",
        "        #row = remove_accents(row)\n",
        "        #row = row.lower()\n",
        "        hl_cleansed.append(row)\n",
        "    return hl_cleansed\n",
        "\n",
        "def keywords_extraction(sent):\n",
        "  rs=\"\"\n",
        "  for i in pos_tag(sent):\n",
        "    if i[1] !='P' and i[1] != 'CH':\n",
        "      rs=rs+' '+i[0]\n",
        "  return rs.strip()\n",
        "\n",
        "\n",
        "def sentences_tokenize(text):\n",
        "    sents = sent_tokenize(text)\n",
        "    sents = [word_tokenize(s,format = 'text') for s in sents]\n",
        "    sents = [remove_punctuation(s) for s in sents]\n",
        "    sents = [s.lower() for s in sents]\n",
        "    #sents = [remove_stopwords(stopwords,s) for s in sents]\n",
        "    return sents\n",
        "\n",
        "## Converting 3D array of array into 1D array \n",
        "def arr_convert_1d(arr): \n",
        "    arr = np.array(arr) \n",
        "    arr = np.concatenate( arr, axis=0 ) \n",
        "    arr = np.concatenate( arr, axis=0 ) \n",
        "    return arr \n",
        "  \n",
        "## Cosine Similarity \n",
        "def cosine(trans): \n",
        "    cos = [] \n",
        "    cos.append(cosine_similarity(trans[0], trans[1])) \n",
        "    return cos\n",
        "\n",
        "def tfidf(str1, str2,tf_idf_vetor,stopwords):\n",
        "    str1=standardize_data([str1],stopwords)\n",
        "    str2=standardize_data([str2],stopwords)  \n",
        "    corpus = [str1[0],str2[0]] \n",
        "    trans = tf_idf_vetor.transform(corpus)\n",
        "    cos=cosine(trans) \n",
        "    return arr_convert_1d(cos)[0]\n",
        "\n",
        "def relevance_ranking(query,data,vect,stopwords):\n",
        "  query=standardize_data([query],stopwords)[0]\n",
        "  print('Query: ',query,'\\n')\n",
        "  score=defaultdict()\n",
        "  i=0\n",
        "  for d in data:\n",
        "    t=tfidf(query, d,vect,stopwords)\n",
        "    if t!=0.0:\n",
        "      score[t]=d\n",
        "    i+=1\n",
        "  return OrderedDict(sorted(score.items(),reverse=True))\n",
        "\n",
        "def whoosh_add_document(data):\n",
        "  #creating the schema\n",
        "  schema = Schema(doc_id=STORED,content=TEXT(stored=True))\n",
        "  #creating the index\n",
        "  if not os.path.exists(\"index\"):\n",
        "      os.mkdir(\"index\")\n",
        "  ix = create_in(\"index\",schema)\n",
        "  ix = open_dir(\"index\")\n",
        "  writer = ix.writer()\n",
        "  for i in range(0,len(data)):\n",
        "    writer.add_document(doc_id=\"doc_\"+str(i+1),content=data[i])\n",
        "  writer.commit()\n",
        "  return ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCvbhr-l4ehW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=load_data('/content/data/data_QA/data')\n",
        "stopwords = set(open('/content/data/data_QA/stopwords/stopwords.txt').read().split(' ')[:-1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QyNMEbyO1NX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "e28684e1-c694-46a3-c058-c1af61cfede9"
      },
      "source": [
        "#Building index\n",
        "data_standard=standardize_data(data,stopwords)\n",
        "vect = TfidfVectorizer(min_df=1, max_df=0.8,max_features=8000,sublinear_tf=True,ngram_range=(1,3)) \n",
        "vect.fit(data_standard)"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=0.8, max_features=8000, min_df=1,\n",
              "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
              "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
              "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
              "        vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY9jZ7wU9p4F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "908d1fc0-6ce3-4f1e-aea3-be646baaa362"
      },
      "source": [
        "query=\"Quang Trung sinh năm bao nhiêu \"\n",
        "query_=keywords_extraction(query)\n",
        "\n",
        "\n",
        "rs=relevant_ranking(query_,data,vect,stopwords)\n",
        "i=0\n",
        "\n",
        "for score,doc in rs.items():\n",
        "  answer = model.predict(doc,query)\n",
        "  num_overlap=len(set(query_.split()) & set(doc.split()))\n",
        "  if answer['confidence']>0.1 and num_overlap >1:\n",
        "    print('\\nQuestion: ',query)\n",
        "    print('\\nOverlap key word: ',num_overlap)\n",
        "    print('\\nAnswer: ',answer['answer'])\n",
        "    print('\\nIR Sccore: ',score)\n",
        "    print('\\nBert Score: ',answer['confidence'])\n",
        "    print('\\nContent: ',doc[:100],'...')\n",
        "    print('\\n==========================================\\n\\n\\n')\n",
        "    i+=1\n",
        "  if i==5:\n",
        "    break"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query:  Quang Trung sinh năm \n",
            "\n",
            "\n",
            "Question:  Quang Trung sinh năm bao nhiêu \n",
            "\n",
            "Overlap key word:  3\n",
            "\n",
            "Answer:  1783\n",
            "\n",
            "IR Sccore:  0.10716875074371207\n",
            "\n",
            "Bert Score:  0.9360089057989387\n",
            "\n",
            "Content:  Nguyễn Quang Toản (sinh Qúi Mão 1783- mất Nhâm Tuất 1802)\n",
            "\n",
            "Cảnh Thịnh Hoàng đế (Thời gian ở ngôi 179 ...\n",
            "\n",
            "==========================================\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question:  Quang Trung sinh năm bao nhiêu \n",
            "\n",
            "Overlap key word:  2\n",
            "\n",
            "Answer:  (…- Tân Mão)\n",
            "\n",
            "IR Sccore:  0.0382599755851343\n",
            "\n",
            "Bert Score:  0.9219120462611116\n",
            "\n",
            "Content:  Triệu Quang Phục (…- Tân Mão)\n",
            "\n",
            "Danh tướng nhà Tiền Lý, con Thái phó Triệu Túc, quê ở Châu Biên, phủ  ...\n",
            "\n",
            "==========================================\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question:  Quang Trung sinh năm bao nhiêu \n",
            "\n",
            "Overlap key word:  2\n",
            "\n",
            "Answer:  1911\n",
            "\n",
            "IR Sccore:  0.022181279576233608\n",
            "\n",
            "Bert Score:  0.9179584638692404\n",
            "\n",
            "Content:  Võ Nguyên Giáp (sinh 1911)\n",
            "\n",
            "Võ Nguyên Giáp (sinh 1911), nhà hoạt động nổi tiếng của Đảng Cộng sản và ...\n",
            "\n",
            "==========================================\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question:  Quang Trung sinh năm bao nhiêu \n",
            "\n",
            "Overlap key word:  3\n",
            "\n",
            "Answer:  1890\n",
            "\n",
            "IR Sccore:  0.018385125506151172\n",
            "\n",
            "Bert Score:  0.9882463846256808\n",
            "\n",
            "Content:  Hồ Chí Minh\n",
            "Cuộc đời của Chủ tịch Hồ Chí Minh là một cuộc đời trong sáng cao đẹp của một người cộng  ...\n",
            "\n",
            "==========================================\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Question:  Quang Trung sinh năm bao nhiêu \n",
            "\n",
            "Overlap key word:  4\n",
            "\n",
            "Answer:  1292 - 1370\n",
            "\n",
            "IR Sccore:  0.01640899873898396\n",
            "\n",
            "Bert Score:  0.7217781194114895\n",
            "\n",
            "Content:  Chu Văn An (1292 - 1370)\n",
            "\n",
            "Chu Văn An - Nhà giáo dục đầu tiên của Việt Nam\n",
            "\n",
            "Chu Văn An (còn gọi là Ch ...\n",
            "\n",
            "==========================================\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}