{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vietnamese-Q&A-wiki.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMF2S8TMl2ebz/B2ChxsPQZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koyomin9zx/UITQA-Vietnamese-Question-Answering/blob/master/Vietnamese_Q%26A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwGlBWUyHxBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Requirements\n",
        "!pip install --upgrade google-api-python-client\n",
        "!pip install nltk\n",
        "!pip install BeautifulSoup\n",
        "!pip install underthesea\n",
        "!pip install sklearn\n",
        "!pip install plotly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byNYORPPIX9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7a24953b-6814-4778-e764-f2bb089cd017"
      },
      "source": [
        "import pickle\n",
        "from googleapiclient.discovery import build\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import timeit\n",
        "import time\n",
        "from multiprocessing import Pool\n",
        "import string\n",
        "import numpy as np\n",
        "from difflib import SequenceMatcher\n",
        "from nltk import sent_tokenize, download\n",
        "from underthesea import word_tokenize\n",
        "from underthesea import ner\n",
        "from collections import defaultdict\n",
        "\n",
        "download('punkt')\n",
        "Seach_api_key =\"AIzaSyBy-PVoHZdYRDU70gsLD-ALy5JabcZUICk\"\n",
        "Custom_Search_Engine_ID =\"013964321510468908374:fcs9cr0koid\"\n",
        "\n",
        "stopwords = set(open('stopwords.txt').read().split('\\n')[:-1]) #set stopword\n",
        "puct_set = set([c for c in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~']) #set puctua\n",
        "\n",
        "def tokenize(text):\n",
        "    sents = sent_tokenize(text)\n",
        "    sents = [word_tokenize(s,format = 'text') for s in sents]\n",
        "    return sents\n",
        "\n",
        "def get_entities(seq):\n",
        "    i = 0\n",
        "    chunks = []\n",
        "    seq = seq + ['O']  # add sentinel\n",
        "    types = [tag.split('-')[-1] for tag in seq]\n",
        "    while i < len(seq):\n",
        "        if seq[i].startswith('B'):\n",
        "            for j in range(i+1, len(seq)):\n",
        "                if seq[j].startswith('I') and types[j] == types[i]:\n",
        "                    continue\n",
        "                break\n",
        "            chunks.append((types[i], i, j))\n",
        "            i = j\n",
        "        else:\n",
        "            i += 1\n",
        "    return chunks\n",
        "\n",
        "def _get_chunks(words, tags):\n",
        "    chunks = get_entities(tags)\n",
        "    res = defaultdict(list)\n",
        "    for chunk_type, chunk_start, chunk_end in chunks:\n",
        "        res[chunk_type].append(' '.join(words[chunk_start: chunk_end]))\n",
        "        print(chunk_type)\n",
        "        print(chunk_start)\n",
        "        print(chunk_end)\n",
        "    return res\n",
        "\n",
        "def ner_extraction(text):\n",
        "    res = ner(text)\n",
        "    words = [r[0] for r in res]\n",
        "    tags = [t[3] for t in res]\n",
        "    \n",
        "    return _get_chunks(words,tags)\n",
        "\n",
        "def generateBigram(words):\n",
        "    bigrams = [words[i] + '_' + words[i+1] for i in range(0,len(words) - 1)]\n",
        "    return bigrams\n",
        "\n",
        "def noiseSent(sent):\n",
        "    if len(sent.split()) <= 3 or len(sent.split()) > 100:\n",
        "        return True\n",
        "    \n",
        "    if len(sent) <= 30:\n",
        "        return True\n",
        "    \n",
        "    if all(ord(c) < 128 for c in sent):\n",
        "        return True\n",
        "    \n",
        "    if not any(c.isalpha() for c in sent):\n",
        "        return True\n",
        "\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sI6LEtLKeI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Passage:\n",
        "    def __init__(self,string,rank,num_key):\n",
        "        self.sent = string            #sentences\n",
        "        self.ner = []                 #named entities\n",
        "        self.num_key = num_key        #number of match keywords\n",
        "        self.len_long_seq = 0         #length of longest exact sequence of question keywords\n",
        "        self.rank = rank              #rank of own document\n",
        "        self.ngram_overlap = 0        #ngram overlap question\n",
        "        self.proximity = 0            #shortest keywords that cover all keywords\n",
        "        self.score = 0                #Overall score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qEauYTNg89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keywords_extraction(sentences):\n",
        "    sent = sentences.lower()\n",
        "    sent = sent.split()\n",
        "    sent = [s for s in sent if s not in stopwords and s not in puct_set]\n",
        "    return sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-zOoQe0NxUq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8e1066d4-4eda-4072-c12a-10ad93dc4861"
      },
      "source": [
        "query = \"Thủ đô của Việt Nam là gì ?\"\n",
        "\n",
        "token_query = tokenize(query)[0]\n",
        "keywords = keywords_extraction(token_query)\n",
        "print(token_query)\n",
        "print('Keywords : ' + ' , '.join(keywords))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thủ_đô của Việt_Nam là gì ?\n",
            "Keywords : thủ_đô , việt_nam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgXmeqVxOvhu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "32868d30-c37a-46f3-e7b7-5c8449fd9bce"
      },
      "source": [
        "start = time.time()\n",
        "service = build(\"customsearch\", \"v1\",developerKey=Seach_api_key)\n",
        "\n",
        "def ggsearch(i):\n",
        "    if (i == 0):\n",
        "        res = service.cse().list(q=query,cx = Custom_Search_Engine_ID).execute()\n",
        "    else:\n",
        "        res = service.cse().list(q=query,cx = Custom_Search_Engine_ID,num=10,start = i*10).execute()\n",
        "    return res['items']\n",
        "\n",
        "#multi processing\n",
        "pool = Pool(4)\n",
        "pages_content = pool.map(ggsearch,range(1))\n",
        "pool.terminate()\n",
        "#pages_content=ggsearch(1)\n",
        "\n",
        "#extract url, title\n",
        "pages_content = [j for i in pages_content for j in i]\n",
        "document_urls = []\n",
        "document_titles = []\n",
        "for page in pages_content:\n",
        "    if 'fileFormat' in page:\n",
        "        print('Skip ' +  page['link'])\n",
        "        continue\n",
        "    document_urls.append(page['link'])\n",
        "    document_titles.append(page[u'title'])\n",
        "    \n",
        "for i in range(0,10):\n",
        "    print(document_titles[i])\n",
        "    print(document_urls[i])\n",
        "\n",
        "print('Number of result: '+str(len(document_titles)))\n",
        "print('Time execute: '+str(time.time() - start))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thủ đô Việt Nam – Wikipedia tiếng Việt\n",
            "https://vi.wikipedia.org/wiki/Th%E1%BB%A7_%C4%91%C3%B4_Vi%E1%BB%87t_Nam\n",
            "Việt Nam Cộng hòa – Wikipedia tiếng Việt\n",
            "https://vi.wikipedia.org/wiki/Vi%E1%BB%87t_Nam_C%E1%BB%99ng_h%C3%B2a\n",
            "Hà Nội – Wikipedia tiếng Việt\n",
            "https://vi.wikipedia.org/wiki/H%C3%A0_N%E1%BB%99i\n",
            "Thảo luận:Thủ đô Việt Nam – Wikipedia tiếng Việt\n",
            "https://vi.wikipedia.org/wiki/Th%E1%BA%A3o_lu%E1%BA%ADn:Th%E1%BB%A7_%C4%91%C3%B4_Vi%E1%BB%87t_Nam\n",
            "Việt Nam – Wikipedia tiếng Việt\n",
            "https://vi.wikipedia.org/wiki/Vi%E1%BB%87t_Nam\n",
            "Thành phố Hồ Chí Minh – Wikipedia tiếng Việt\n",
            "https://vi.wikipedia.org/wiki/Th%C3%A0nh_ph%E1%BB%91_H%E1%BB%93_Ch%C3%AD_Minh\n",
            "Việt Nam Dân chủ Cộng hòa – Wikipedia tiếng Việt\n",
            "https://vi.wikipedia.org/wiki/Vi%E1%BB%87t_Nam_D%C3%A2n_ch%E1%BB%A7_C%E1%BB%99ng_h%C3%B2a\n",
            "Thủ đô – Wikipedia tiếng Việt\n",
            "https://vi.wikipedia.org/wiki/Th%E1%BB%A7_%C4%91%C3%B4\n",
            "Chăm Pa – Wikipedia tiếng Việt\n",
            "https://vi.wikipedia.org/wiki/Ch%C4%83m_Pa\n",
            "Biệt khu Thủ đô – Wikipedia tiếng Việt\n",
            "https://vi.wikipedia.org/wiki/Bi%E1%BB%87t_khu_Th%E1%BB%A7_%C4%91%C3%B4\n",
            "Number of result: 10\n",
            "Time execute: 0.9449558258056641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS1yLfL6UBQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}